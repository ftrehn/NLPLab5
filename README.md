# Телеграм-бот с локальной LLM с поддержкой контекста

Проект Telegram-бота, который использует локальную языковую модель (LLM) через LM Studio для общения с пользователями. Бот поддерживает сохранение контекста диалога и возможность его очистки.

## Описание
Цель работы — развертывание локальной LLM и реализация механизма управления контекстом диалога.

**Функционал:**
* Интеграция с LM Studio (Local Server).
* Сохранение истории переписки для каждого пользователя отдельно.
* Команда `/clear` для сброса контекста (эффект "амнезии").
* Команда `/model` для проверки названия текущей модели.

## Требования
* Python 3.8+
* [LM Studio](https://lmstudio.ai/)
* Аккаунт в Telegram и токен от @BotFather

## Установка и запуск

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/ftrehn/NLPLab5
    cd NLPLab5
    ```

2.  **Установите зависимости:**
    ```bash
    pip install pytelegrambotapi requests jsons
    ```

3.  **Настройка LM Studio:**
    * Загрузите модель (рекомендуется `Qwen2.5-1.5B-Instruct` или аналогичная).
    * Перейдите во вкладку **Local Server** (<->).
    * Нажмите **Start Server**. Убедитесь, что сервер доступен по адресу `http://localhost:1234`.

4.  **Настройка бота:**
    * Откройте файл `main.py`.
    * Найдите переменную `API_TOKEN` и вставьте свой токен:
        ```python
        API_TOKEN = 'ВАШ_ТОКЕН_ОТ_BOTFATHER'
        ```

5.  **Запуск:**
    ```bash
    python main.py
    ```

## Команды бота
* `/start` — Приветствие.
* `/clear` — Очистить историю диалога (сброс контекста).
* `/model` — Узнать название текущей подключенной модели.
